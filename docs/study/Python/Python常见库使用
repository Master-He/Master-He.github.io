# fastavro

使用步骤

```
1. 生成schema文件
2. 根据schema, 写avro文件
3. 根据schema, 读avro文件
```

1. 生成alert.avsc文件

   ```json
   {
   	"namespace": "org.example",
   	"type": "record",
   	"name": "Alert",
   	"fields": [
   		{"name": "ruleid", "type": "string"},
   		{"name": "ts", "type": "long"},
   		{"name": "result", "type": "string"},
   		{"name": "type", "type": ["null", "string"], "default":null}
   	]
   }
   ```

2. 根据schema, 写avro文件
   ```python
   import os
   from fastavro.schema import load_schema
   from fastavro import writer
   
   dir_path = os.path.dirname(os.path.abspath(__file__))
   alert_avsc = os.path.join(dir_path, "alert.avsc")
   
   schema = load_schema(alert_avsc)
   
   records = [
       {
           u'ruleid': u'117891001',
           u'ts': 1433269388,
           u'result': u'result'
       }
]
   
   out_avro = os.path.join(dir_path, "alert.avro")
   with open(out_avro, 'wb') as out:
       writer(out, schema, records)
   
   ```
   
3.  根据schema, 读avro文件

   ```python
   import os
   from fastavro.schema import load_schema
   from fastavro import reader
   
   dir_path = os.path.dirname(os.path.abspath(__file__))
   alert_avsc = os.path.join(dir_path, "alert.avsc")
   
   schema = load_schema(alert_avsc)
   
   alert_avro = os.path.join(dir_path, "alert.avro")
   with open(alert_avro, 'rb') as avro_file:
       avro_reader = reader(avro_file, schema)
       for record in avro_reader:
           print(record.get("ruleid"))
   
   ```

avro IO读写

```python
import os
from fastavro.schema import load_schema
from fastavro import writer, reader
from io import BytesIO

dir_path = os.path.dirname(os.path.abspath(__file__))
alert_avsc = os.path.join(dir_path, "alert.avsc")

schema = load_schema(alert_avsc)

records = [
    {
        u'ruleid': u'123456789',
        u'ts': 1433269388,
        u'result': u'result',
        u'type': u'type'
    }
]


fo = BytesIO()
writer(fo, schema, records)


fo.seek(0)
for record in reader(fo):
    print(record)

```



# argparse

参数解析库



# fcntl

文件锁

```
PID_FILE = open(DATA_PID_FILE, 'w')
fcntl.flock(PID_FILE, fcntl.LOCK_EX) # 加锁
fcntl.flock(PID_FILE, fcntl.LOCK_UN) # 解锁
PID_FILE.close()
```



# requests

```python

```



# json

参考链接：https://www.jianshu.com/p/90ecc5987a18

1.直接输出字典中文
 在python中经常遇见直接print dict（字典），或者dict转json，但是没有给特定的参数，然后打印json字符串，输出的中文就成了unicode码的情况，如下：

```bash
d = {'name': '张三', 'age': '1'}
print d
jd = json.dumps(d)
print jd
```

输出结果为

```bash
{'age': '1', 'name': '\xe5\xbc\xa0\xe4\xb8\x89'}
{"age": "1", "name": "\u5f20\u4e09"}
```

这种情况怎么办呢？
 要将字典中的中文正确的输出，可以将d转换成json字符串，转换时使用json.dumps(d, ensure_ascii=False, encoding='utf-8'))

```php
d = {'name': '张三', 'age': '1'}
print d
jd = json.dumps(d, ensure_ascii=False, encoding='utf-8'))
print jd
```

输出结果为：

```bash
{'age': '1', 'name': '\xe5\xbc\xa0\xe4\xb8\x89'}
{"age": "1", "name": "张三"}
```



python2 : How to get string objects instead of Unicode from JSON

https://stackoverflow.com/questions/956867/how-to-get-string-objects-instead-of-unicode-from-json



## 如何保证读取json是保证原有字段顺序

参考： https://blog.csdn.net/IT8343/article/details/112868710

```python
import json
from collections import OrderedDict
 
 
with open("123.json", "r", encoding="utf-8") as f:
    jsonData = json.load(f,object_pairs_hook=OrderedDict)
    print(jsonData)
    jsonData["ID"] = "50"
with open("66.json", "w", encoding="utf-8") as f:
    json.dump(jsonData, f)
```



## 在指定位置增加key value



## 自定义json  key 顺序

https://stackoverflow.com/questions/18871217/how-to-custom-sort-a-list-of-dict-to-use-in-json-dumps

```python
#!/usr/bin/env python
# encoding: utf-8
from collections import OrderedDict
import json
# 参考 https://stackoverflow.com/questions/18871217/how-to-custom-sort-a-list-of-dict-to-use-in-json-dumps
allsites = [
    {
        'A5': 'G',
        'A10': 'G',
        'site': 'example1.com',
        'A1': 'G'
    },
    {
        'A5': 'R',
        'A10': 'Y',
        'site': 'example2.com',
        'A1': 'G'
    }
]

sort_order = ['site', 'A1', 'A5', 'A10']

allsites_ordered = [OrderedDict(sorted(item.items(), key=lambda item: sort_order.index(item[0])))
                    for item in allsites]

data = {'Author': "joe", 'data': allsites_ordered}
print(json.dumps(data, indent=4, separators=(',', ': ')))
```





# csv

```python
with open(mid_hole_id_map_path, "r") as f:
	csv.DictReader(f)
```



# 代码混淆库

pyarmor 库

https://pyarmor.readthedocs.io/en/latest/

